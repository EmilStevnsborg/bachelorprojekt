{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing homemade layers\n",
    "\n",
    "This notebook contains tests for all the homemade layers. The tests takes some samples from the mni-\n",
    "st dataset as a minibatch and compares the results from running this minibatch through the test CNN\n",
    "to running the same minibatch through the homemade layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/emil/Documents/bachelor/bachelorprojekt/Python\n"
     ]
    }
   ],
   "source": [
    "#importing relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "%cd ..\n",
    "\n",
    "from CNN_small_architecture import CNNSmall\n",
    "from Tests.helper_functions import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_test = datasets.MNIST(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_set = [[data[0], tokenize(data[1])] for data in MNIST_test if data[1] in [1,2]][:1000]\n",
    "\n",
    "batch_size = 1\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_original = CNNSmall()\n",
    "model_original.eval()\n",
    "\n",
    "path = \"CNN_small\"\n",
    "load = True\n",
    "\n",
    "if load and os.path.isfile(path):\n",
    "    model_original.load_state_dict(torch.load(path))\n",
    "\n",
    "preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        image, label = data\n",
    "        output = model_original(image)\n",
    "        if torch.argmax(output) == torch.argmax(label):\n",
    "            preds.append(1)\n",
    "        else:\n",
    "            preds.append(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.count(1)/len(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f31e8003a22d1d43deb930c821e4af1d8090c97ed08fe8384c28a99b74fb445c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
