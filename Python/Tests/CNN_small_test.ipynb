{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing homemade layers\n",
    "\n",
    "This notebook contains tests for all the homemade layers. The tests takes some samples from the mni-\n",
    "st dataset as a minibatch and compares the results from running this minibatch through the test CNN\n",
    "to running the same minibatch through the homemade layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emil/anaconda3/envs/dl/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libc10_cuda.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/emil/Documents/bachelor/bachelorprojekt/Python\n"
     ]
    }
   ],
   "source": [
    "#importing relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "%cd ..\n",
    "\n",
    "from CNN_small_architecture import CNNSmall\n",
    "from CNN_layers import conv_homemade\n",
    "from CNN_layers import maxpool_homemade\n",
    "from CNN_layers import batchnorm_homemade\n",
    "from CNN_layers import linear_layer_homemade\n",
    "from CNN_layers import elu_homemade\n",
    "from CNN_layers import relu_homemade as ReLU\n",
    "from Tests.helper_functions import tokenize, transform_input, compare, create_conv_homemade, \\\n",
    "                                create_batchnorm_homemade, create_maxpool_homemade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_test = datasets.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_set = [[data[0], tokenize(data[1])] for data in MNIST_test if data[1] in [1,2]]\n",
    "\n",
    "batch_size = 2\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_original = CNNSmall()\n",
    "model_original.eval()\n",
    "\n",
    "path = \"CNN_small\"\n",
    "load = True\n",
    "\n",
    "if load and os.path.isfile(path):\n",
    "    model_original.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_original_test, label_test = next(iter(test_loader))\n",
    "input_homemade_test = transform_input(input_batch=input_original_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRIDE ER PRÆDEFINERET\n",
      "STRIDE ER PRÆDEFINERET\n"
     ]
    }
   ],
   "source": [
    "elu_homemade = elu_homemade.ELU()\n",
    "relu_homemade = ReLU.relu()\n",
    "conv1_homemade = create_conv_homemade(model_conv= model_original.conv1)\n",
    "batchnorm1_homemade = create_batchnorm_homemade(model_batchnorm= model_original.batchNorm1)\n",
    "maxpool1_homemade = create_maxpool_homemade(model_maxpool= model_original.maxPool1)\n",
    "conv2_homemade = create_conv_homemade(model_conv= model_original.conv2)\n",
    "batchnorm2_homemade = create_batchnorm_homemade(model_batchnorm= model_original.batchNorm2)\n",
    "maxpool2_homemade = create_maxpool_homemade(model_original.maxPool2)\n",
    "linear_homemade = linear_layer_homemade.linear_layer(model_original.lin.weight,model_original.lin.bias,2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape of the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3605, -0.2362,  0.1336])\n"
     ]
    }
   ],
   "source": [
    "print(model_original.batchNorm1.running_mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the first convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homemade conv1 filter on test\n",
    "out_homemade = conv1_homemade(input_homemade_test)\n",
    "# original conv1 filter on test\n",
    "out_original = model_original.conv1(input_original_test)\n",
    "\n",
    "print(\"Convolutional layer 1 error over out channels: \")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the first Batchnorm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homemade batchNorm1 filter on test\n",
    "out_homemade = batchnorm1_homemade(input_batch=out_homemade)\n",
    "# original batchNorm1 filter on test\n",
    "out_original = model_original.batchNorm1(out_original)\n",
    "\n",
    "print(\"BatchNorm layer 1 error over out channels: \")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the first ReLU layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_homemade = relu_homemade(out_homemade)\n",
    "\n",
    "out_original = model_original.relu1(out_original)\n",
    "\n",
    "print(\"ReLU layer 1 error over out channels\")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the first Maxpool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homemade MaxPool filter on test\n",
    "out_homemade = maxpool1_homemade(input_batch=out_homemade)\n",
    "# original MaxPool filter on test\n",
    "out_original = model_original.maxPool1(out_original)\n",
    "\n",
    "print(\"MaxPool layer 1 error over out channels: \")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the second Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test the second convolutional layer\n",
    "\n",
    "# homemade batchNorm1 filter on test\n",
    "out_homemade = conv2_homemade(input_batch=out_homemade)\n",
    "# original batchNorm1 filter on test\n",
    "out_original = model_original.conv2(out_original)\n",
    "\n",
    "print(\"MaxPool layer 1 error over out channels: \")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the second Batchnorm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homemade batchNorm1 filter on test\n",
    "out_homemade = batchnorm2_homemade(input_batch=out_homemade)\n",
    "# original batchNorm1 filter on test\n",
    "out_original = model_original.batchNorm2(out_original)\n",
    "\n",
    "print(\"MaxPool layer 1 error over out channels: \")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the second Maxpool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homemade batchNorm1 filter on test\n",
    "out_homemade = maxpool2_homemade(input_batch=out_homemade)\n",
    "# original batchNorm1 filter on test\n",
    "out_original = model_original.maxPool2(out_original)\n",
    "\n",
    "print(\"MaxPool layer 1 error over out channels: \")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homemade linear filter on test\n",
    "out_homemade = linear_homemade(torch.reshape(torch.tensor(out_homemade, dtype = torch.double),(2,45)))\n",
    "# original linear filter on test\n",
    "out_original = model_original.lin(torch.reshape(out_original, (2,45)))\n",
    "\n",
    "print(\"Linear layer 1 error over out channels: \")\n",
    "compare(out_homemade.numpy(), list(list(out_original.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = nn.ReLU()\n",
    "homemade = ReLU.relu()\n",
    "\n",
    "print(relu(torch.tensor([0,1,2,-3,-0.32543254,5,6,7])))\n",
    "print(homemade([[[[0,1,2,-3,0.546547,5,6,7]]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f31e8003a22d1d43deb930c821e4af1d8090c97ed08fe8384c28a99b74fb445c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
