{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing homemade layers\n",
    "\n",
    "This notebook contains tests for all the homemade layers. The tests takes some samples from the mni-\n",
    "st dataset as a minibatch and compares the results from running this minibatch through the test CNN\n",
    "to running the same minibatch through the homemade layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "from CNN_small_architecture import CNNSmall\n",
    "from CNN_layers import conv_homemade\n",
    "from CNN_layers import maxpool_homemade\n",
    "from CNN_layers import batchnorm_homemade\n",
    "from CNN_layers import linear_layer_homemade\n",
    "from CNN_layers import elu_homemade\n",
    "from CNN_layers import relu_homemade as ReLU\n",
    "from Tests.helper_functions import tokenize, transform_input, compare, create_conv_homemade, \\\n",
    "                                create_batchnorm_homemade, create_maxpool_homemade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_test = datasets.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_set = [[data[0], tokenize(data[1])] for data in MNIST_test if data[1] in [1,2]]\n",
    "\n",
    "batch_size = 2\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_original = CNNSmall()\n",
    "model_original.eval()\n",
    "\n",
    "path = \"CNN_small\"\n",
    "load = True\n",
    "\n",
    "if load and os.path.isfile(path):\n",
    "    model_original.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_original_test, label_test = next(iter(test_loader))\n",
    "input_homemade_test = transform_input(input_batch=input_original_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRIDE ER PRÆDEFINERET\n",
      "STRIDE ER PRÆDEFINERET\n"
     ]
    }
   ],
   "source": [
    "elu_homemade = elu_homemade.ELU()\n",
    "relu_homemade = ReLU.relu()\n",
    "conv1_homemade = create_conv_homemade(model_conv= model_original.conv1)\n",
    "batchnorm1_homemade = create_batchnorm_homemade(model_batchnorm= model_original.batchNorm1)\n",
    "maxpool1_homemade = create_maxpool_homemade(model_maxpool= model_original.maxPool1)\n",
    "conv2_homemade = create_conv_homemade(model_conv= model_original.conv2)\n",
    "batchnorm2_homemade = create_batchnorm_homemade(model_batchnorm= model_original.batchNorm2)\n",
    "maxpool2_homemade = create_maxpool_homemade(model_original.maxPool2)\n",
    "linear_homemade = linear_layer_homemade.linear_layer(model_original.lin.weight,model_original.lin.bias,2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape of the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNSmall(\n",
      "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (batchNorm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (maxPool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (batchNorm2): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (maxPool2): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "  (lin): Linear(in_features=45, out_features=2, bias=True)\n",
      "  (network): Sequential(\n",
      "    (0): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Linear(in_features=45, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_original)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the first convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional layer 1 error over out channels: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2.714658446367757e-06, 2.784962947907643e-06, 1.9446338829220977e-06],\n",
       " [5.921787107621146e-06, 4.750881298247467e-06, 3.3989394729316835e-06]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# homemade conv1 filter on test\n",
    "out_homemade = conv1_homemade(input_homemade_test)\n",
    "# original conv1 filter on test\n",
    "out_original = model_original.conv1(input_original_test)\n",
    "\n",
    "print(\"Convolutional layer 1 error over out channels: \")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the first Batchnorm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm layer 1 error over out channels: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[4.330277442932129e-05, 2.0656734704971313e-05, 7.69440084695816e-05],\n",
       " [5.023926496505737e-05, 3.732740879058838e-05, 7.526762783527374e-05]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# homemade batchNorm1 filter on test\n",
    "out_homemade = batchnorm1_homemade(input_batch=out_homemade)\n",
    "# original batchNorm1 filter on test\n",
    "out_original = model_original.batchNorm1(out_original)\n",
    "\n",
    "print(\"BatchNorm layer 1 error over out channels: \")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the first ReLU layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU layer 1 error over out channels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[8.52346420288086e-06, 1.2625008821487427e-05, 6.531365215778351e-05],\n",
       " [1.8537044525146484e-05, 1.92299485206604e-05, 5.605258047580719e-05]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_homemade = relu_homemade(out_homemade)\n",
    "\n",
    "out_original = model_original.relu1(out_original)\n",
    "\n",
    "print(\"ReLU layer 1 error over out channels\")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the first Maxpool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool layer 1 error over out channels: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3.3602118492126465e-06, 6.295740604400635e-06, 1.7449259757995605e-05],\n",
       " [7.860362529754639e-06, 8.106231689453125e-06, 1.5363097190856934e-05]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# homemade MaxPool filter on test\n",
    "out_homemade = maxpool1_homemade(input_batch=out_homemade)\n",
    "# original MaxPool filter on test\n",
    "out_original = model_original.maxPool1(out_original)\n",
    "\n",
    "print(\"MaxPool layer 1 error over out channels: \")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the second Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool layer 1 error over out channels: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[7.265901361658278e-06,\n",
       "  6.0008974384351266e-06,\n",
       "  6.8729584533633314e-06,\n",
       "  8.080163430713994e-06,\n",
       "  6.1661622124398185e-06],\n",
       " [9.889932549300706e-06,\n",
       "  8.173251276083482e-06,\n",
       "  8.50474784619415e-06,\n",
       "  1.0051189772125602e-05,\n",
       "  7.640689441951176e-06]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: test the second convolutional layer\n",
    "\n",
    "# homemade batchNorm1 filter on test\n",
    "out_homemade = conv2_homemade(input_batch=out_homemade)\n",
    "# original batchNorm1 filter on test\n",
    "out_original = model_original.conv2(out_original)\n",
    "\n",
    "print(\"MaxPool layer 1 error over out channels: \")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the second Batchnorm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool layer 1 error over out channels: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2.3447908461093903e-05,\n",
       "  2.220645546913147e-05,\n",
       "  2.6049092411994934e-05,\n",
       "  2.2366642951965332e-05,\n",
       "  1.528114080429077e-05],\n",
       " [3.1970441341400146e-05,\n",
       "  3.1556934118270874e-05,\n",
       "  2.845749258995056e-05,\n",
       "  2.7514994144439697e-05,\n",
       "  1.93864107131958e-05]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# homemade batchNorm1 filter on test\n",
    "out_homemade = batchnorm2_homemade(input_batch=out_homemade)\n",
    "# original batchNorm1 filter on test\n",
    "out_original = model_original.batchNorm2(out_original)\n",
    "\n",
    "print(\"MaxPool layer 1 error over out channels: \")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the second Maxpool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool layer 1 error over out channels: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3.777444362640381e-06,\n",
       "  2.9802322387695312e-06,\n",
       "  3.341585397720337e-06,\n",
       "  1.9669532775878906e-06,\n",
       "  2.376735210418701e-06],\n",
       " [4.76837158203125e-06,\n",
       "  3.129243850708008e-06,\n",
       "  3.933906555175781e-06,\n",
       "  1.6093254089355469e-06,\n",
       "  2.816319465637207e-06]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# homemade batchNorm1 filter on test\n",
    "out_homemade = maxpool2_homemade(input_batch=out_homemade)\n",
    "# original batchNorm1 filter on test\n",
    "out_original = model_original.maxPool2(out_original)\n",
    "\n",
    "print(\"MaxPool layer 1 error over out channels: \")\n",
    "compare(out_homemade, transform_input(input_batch = out_original))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear layer 1 error over out channels: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sture\\AppData\\Local\\Temp\\ipykernel_18508\\3903311325.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  out_homemade = linear_homemade(torch.reshape(torch.tensor(out_homemade, dtype = torch.double),(2,45)))\n",
      "C:\\Users\\sture\\Documents\\Studie\\Bachelor\\bachelorprojekt\\Python\\CNN_layers\\linear_layer_homemade.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tmp = torch.dot(input[n],torch.tensor(self.weights[i], dtype = torch.double)) + torch.tensor(self.bias[i], dtype = torch.double)\n",
      "C:\\Users\\sture\\Documents\\Studie\\Bachelor\\bachelorprojekt\\Python\\CNN_layers\\linear_layer_homemade.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tmp = torch.hstack((tmp,(torch.dot(input[n],torch.tensor(self.weights[i], dtype = torch.double)) + torch.tensor(self.bias[i], dtype = torch.double))))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[7.292877981512902e-07, 6.724754975095948e-07],\n",
       " [5.000813505517954e-07, 4.0577709903288905e-07]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# homemade linear filter on test\n",
    "out_homemade = linear_homemade(torch.reshape(torch.tensor(out_homemade, dtype = torch.double),(2,45)))\n",
    "# original linear filter on test\n",
    "out_original = model_original.lin(torch.reshape(out_original, (2,45)))\n",
    "\n",
    "print(\"Linear layer 1 error over out channels: \")\n",
    "compare(out_homemade.numpy(), list(list(out_original.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 0., 0., 5., 6., 7.])\n",
      "[[[[0.       1.       2.       0.       0.546547 5.       6.\n",
      "    7.      ]]]]\n"
     ]
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "homemade = ReLU.relu()\n",
    "\n",
    "print(relu(torch.tensor([0,1,2,-3,-0.32543254,5,6,7])))\n",
    "print(homemade([[[[0,1,2,-3,0.546547,5,6,7]]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f31e8003a22d1d43deb930c821e4af1d8090c97ed08fe8384c28a99b74fb445c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
