{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/emil/Documents/bachelor/bachelorprojekt/Python\n"
     ]
    }
   ],
   "source": [
    "#importing relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import torch.quantization\n",
    "import copy\n",
    "\n",
    "%cd ..\n",
    "\n",
    "from CNN_small_architecture import CNNSmall\n",
    "from Tests.helper_functions import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_test = datasets.MNIST(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "test_set = [[data[0], tokenize(data[1])] for data in MNIST_test if data[1] in [1,2]][:1000]\n",
    "\n",
    "batch_size = 1\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_original = CNNSmall()\n",
    "\n",
    "path = \"CNN_small\"\n",
    "load = True\n",
    "\n",
    "if load and os.path.isfile(path):\n",
    "    model_original.load_state_dict(torch.load(path))\n",
    "\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    copy.deepcopy(model_original), qconfig_spec={nn.Conv2d, nn.BatchNorm2d, nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "quantized_model.eval()\n",
    "\n",
    "preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNSmall(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (batchNorm1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (maxPool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (batchNorm2): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (maxPool2): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "  (lin): DynamicQuantizedLinear(in_features=45, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (5): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=(3, 3), stride=(3, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Flatten(start_dim=1, end_dim=-1)\n",
       "    (9): DynamicQuantizedLinear(in_features=45, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        image, label = data\n",
    "        output = quantized_model(image)\n",
    "        if torch.argmax(output) == torch.argmax(label):\n",
    "            preds.append(1)\n",
    "        else:\n",
    "            preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.count(1)/len(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
